{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMtJu9TW9GceNLmCL7QpmSD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"NH32i9KOFuOZ"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","import tarfile\n","import os\n","import shutil\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","import tensorflow as tf\n","\n","os.makedirs(\"/content/images\", exist_ok=True)\n","os.makedirs(\"/content/annotations_lvl1\", exist_ok=True)\n","\n","images_tar_path = \"/content/drive/MyDrive/oxford_pets/images.tar.gz\"\n","annotations_tar_path = \"/content/drive/MyDrive/oxford_pets/annotations.tar.gz\"\n","\n","with tarfile.open(images_tar_path, 'r:gz') as tar:\n","    tar.extractall(path=\"/content/images\")\n","\n","with tarfile.open(annotations_tar_path, 'r:gz') as tar:\n","    tar.extractall(path=\"/content/annotations_lvl1\")\n","\n","annotations_path = \"/content/annotations_lvl1/annotations/list.txt\"\n","\n","with open(annotations_path, \"r\") as f:\n","    lines = f.readlines()\n","\n","image_label_pairs = []\n","for line in lines:\n","    if line.startswith(\"#\"):\n","        continue\n","    parts = line.strip().split()\n","    image_name = parts[0] + \".jpg\"\n","    label_id = int(parts[1]) - 1\n","    image_label_pairs.append((image_name, label_id))\n","\n","train_data, val_data = train_test_split(\n","    image_label_pairs,\n","    test_size=0.2,\n","    stratify=[lbl for _, lbl in image_label_pairs]\n",")\n","\n","base_dir = \"/content/oxford_pets_processed\"\n","for phase in ['train', 'val']:\n","    for class_id in range(37):\n","        os.makedirs(f\"{base_dir}/{phase}/{class_id}\", exist_ok=True)\n","\n","images_path = \"/content/images/images\"\n","\n","def copy_images(data, phase):\n","    for fname, label in data:\n","        src = os.path.join(images_path, fname)\n","        dst = os.path.join(base_dir, phase, str(label), fname)\n","        if os.path.exists(src):\n","            shutil.copyfile(src, dst)\n","\n","copy_images(train_data, 'train')\n","copy_images(val_data, 'val')\n","\n","image_size = (224, 224)\n","batch_size = 32\n","\n","datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_gen = datagen.flow_from_directory(\n","    f\"{base_dir}/train\",\n","    target_size=image_size,\n","    batch_size=batch_size,\n","    class_mode='sparse'\n",")\n","\n","val_gen = datagen.flow_from_directory(\n","    f\"{base_dir}/val\",\n","    target_size=image_size,\n","    batch_size=batch_size,\n","    class_mode='sparse'\n",")\n","\n","model = Sequential([\n","    Conv2D(32, (3,3), activation='relu', input_shape=(224,224,3)),\n","    MaxPooling2D(2,2),\n","    Conv2D(64, (3,3), activation='relu'),\n","    MaxPooling2D(2,2),\n","    Flatten(),\n","    Dense(128, activation='relu'),\n","    Dense(37, activation='softmax')\n","])\n","\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","model.fit(train_gen, validation_data=val_gen, epochs=5)\n","\n"]}]}